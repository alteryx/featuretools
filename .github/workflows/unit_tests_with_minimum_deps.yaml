name: Unit Tests - Minimum Dependencies
on:
  pull_request:
    types: [opened, synchronize]
  push:
    branches:
      - main
  workflow_dispatch:
jobs:
  py38_unit_tests_minimum_dependencies:
    name: Unit Tests - 3.8 Minimum Dependencies
    runs-on: ubuntu-latest
    strategy:
      matrix:
        libraries: ["core", "spark - misc", "spark - computational", "spark - entityset_1", "spark - entityset_2", "spark - primitives"]
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
        with:
          ref: ${{ github.event.pull_request.head.ref }}
          repository: ${{ github.event.pull_request.head.repo.full_name }}
      - uses: actions/setup-python@v4
        with:
          python-version: 3.8
      - name: Config pip, upgrade pip, and install graphviz
        run: |
          sudo apt update
          sudo apt install -y graphviz
          pip config --site set global.progress_bar off
          python -m pip install --upgrade pip
          python -m pip install wheel
      - name: Install featuretools with no dependencies
        run: |
          python -m pip install -e . --no-dependencies
      - if: ${{ startsWith(matrix.libraries, 'spark') }}
        name: Install numpy for spark
        run: |
          NUMPY_VERSION=$(cat featuretools/tests/requirement_files/minimum_spark_requirements.txt | grep numpy)
          python -m pip uninstall numpy -y
          python -m pip install $NUMPY_VERSION --no-build-isolation
      - if: ${{ matrix.libraries == 'core' }}
        name: Install numpy for core
        run: |
          NUMPY_VERSION=$(cat featuretools/tests/requirement_files/minimum_core_requirements.txt | grep numpy)
          python -m pip uninstall numpy -y
          python -m pip install $NUMPY_VERSION --no-build-isolation
      - name: Install featuretools - minimum tests dependencies
        run: |
          python -m pip install -r featuretools/tests/requirement_files/minimum_test_requirements.txt
      - if: ${{ matrix.libraries == 'spark' }}
        name: Install featuretools - minimum spark, core dependencies
        run: |
          sudo apt install -y openjdk-11-jre-headless
          JAVA_HOME="/usr/lib/jvm/java-11-openjdk-amd64"
          python -m pip install -r featuretools/tests/requirement_files/minimum_spark_requirements.txt
      - if: ${{ matrix.libraries == 'core' }}
        name: Install featuretools - minimum core dependencies
        run: |
          python -m pip install -r featuretools/tests/requirement_files/minimum_core_requirements.txt
      - if: ${{ matrix.libraries == 'core' }}
        name: Run unit tests without code coverage
        run: python -m pytest -x -n auto featuretools/tests/
      - if: ${{ matrix.libraries == 'spark - misc' }}
        name: Run unit tests (misc)
        run: pytest featuretools/ -n auto --ignore=featuretools/tests/computational_backend --ignore=featuretools/tests/entityset_tests --ignore=featuretools/tests/primitive_tests
      - if: ${{ matrix.libraries == 'spark - computational' }}
        name: Run unit tests (computational backend)
        run: pytest featuretools/tests/computational_backend/ -n auto
      - if: ${{ matrix.libraries == 'spark - entityset_1' }}
        name: Run unit tests (entityset batch 1)
        run: pytest featuretools/tests/entityset_tests -n auto --ignore=featuretools/tests/entityset_tests/test_es.py --ignore=featuretools/tests/entityset_tests/test_ww_es.py
      - if: ${{ matrix.libraries == 'spark - entityset_2' }}
        name: Run unit tests (entityset batch 2)
        run: pytest featuretools/tests/entityset_tests/test_es.py featuretools/tests/entityset_tests/test_ww_es.py
      - if: ${{ matrix.libraries == 'spark - primitives' }}
        name: Run unit tests (primitives)
        run: pytest featuretools/tests/primitive_tests -n auto
