{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4e63730",
   "metadata": {},
   "source": [
    "Handling Time\n",
    "=============\n",
    "\n",
    "When performing feature engineering with temporal data, carefully selecting the data that is used for any calculation is paramount. By annotating :term:`entities <entity>` with a **time index** column and providing a **cutoff time** during feature calculation, Featuretools will automatically filter out any data after the cutoff time before running any calculations.\n",
    "\n",
    "What is the Time Index?\n",
    "-----------------------\n",
    "\n",
    "The time index is the column in the data that specifies when the data in each row became known. For example, let's examine a table of customer transactions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28317629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --> possibly suppress?        \n",
    "import pandas as pd\n",
    "\n",
    "pd.options.display.max_columns = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2e03cfd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>session_id</th>\n",
       "      <th>transaction_time</th>\n",
       "      <th>product_id</th>\n",
       "      <th>amount</th>\n",
       "      <th>_ft_last_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>298</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-01-01 00:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>127.64</td>\n",
       "      <td>2014-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-01-01 00:01:05</td>\n",
       "      <td>2</td>\n",
       "      <td>109.48</td>\n",
       "      <td>2014-01-01 00:01:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>308</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-01-01 00:02:10</td>\n",
       "      <td>3</td>\n",
       "      <td>95.06</td>\n",
       "      <td>2014-01-01 00:02:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>116</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-01-01 00:03:15</td>\n",
       "      <td>4</td>\n",
       "      <td>78.92</td>\n",
       "      <td>2014-01-01 00:03:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>371</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-01-01 00:04:20</td>\n",
       "      <td>3</td>\n",
       "      <td>31.54</td>\n",
       "      <td>2014-01-01 00:04:20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     transaction_id  session_id    transaction_time product_id  amount  \\\n",
       "298             298           1 2014-01-01 00:00:00          5  127.64   \n",
       "2                 2           1 2014-01-01 00:01:05          2  109.48   \n",
       "308             308           1 2014-01-01 00:02:10          3   95.06   \n",
       "116             116           1 2014-01-01 00:03:15          4   78.92   \n",
       "371             371           1 2014-01-01 00:04:20          3   31.54   \n",
       "\n",
       "          _ft_last_time  \n",
       "298 2014-01-01 00:00:00  \n",
       "2   2014-01-01 00:01:05  \n",
       "308 2014-01-01 00:02:10  \n",
       "116 2014-01-01 00:03:15  \n",
       "371 2014-01-01 00:04:20  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import featuretools as ft\n",
    "es = ft.demo.load_mock_customer(return_entityset=True, random_seed=0)\n",
    "es['transactions'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3a3635",
   "metadata": {},
   "source": [
    "In this table, there is one row for every transaction and a ``transaction_time`` column that specifies when the transaction took place. This means that ``transaction_time`` is the time index because it indicates when the information in each row became known and available for feature calculations.\n",
    "\n",
    "However, not every datetime column is a time index. Consider the ``customers`` entity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6035cdac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>join_date</th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>_ft_last_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>60091</td>\n",
       "      <td>2010-07-17 05:27:50</td>\n",
       "      <td>1984-07-28</td>\n",
       "      <td>2014-01-01 08:09:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>60091</td>\n",
       "      <td>2011-04-08 20:08:14</td>\n",
       "      <td>2006-08-15</td>\n",
       "      <td>2014-01-01 05:31:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>60091</td>\n",
       "      <td>2011-04-17 10:48:33</td>\n",
       "      <td>1994-07-18</td>\n",
       "      <td>2014-01-01 07:26:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>13244</td>\n",
       "      <td>2011-08-13 15:42:34</td>\n",
       "      <td>2003-11-21</td>\n",
       "      <td>2014-01-01 09:00:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>13244</td>\n",
       "      <td>2012-04-15 23:31:04</td>\n",
       "      <td>1986-08-18</td>\n",
       "      <td>2014-01-01 08:23:45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id zip_code           join_date date_of_birth       _ft_last_time\n",
       "5            5    60091 2010-07-17 05:27:50    1984-07-28 2014-01-01 08:09:40\n",
       "4            4    60091 2011-04-08 20:08:14    2006-08-15 2014-01-01 05:31:30\n",
       "1            1    60091 2011-04-17 10:48:33    1994-07-18 2014-01-01 07:26:20\n",
       "3            3    13244 2011-08-13 15:42:34    2003-11-21 2014-01-01 09:00:35\n",
       "2            2    13244 2012-04-15 23:31:04    1986-08-18 2014-01-01 08:23:45"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es['customers']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb74be9e",
   "metadata": {},
   "source": [
    "\n",
    "Here, we have two time columns, ``join_date`` and ``date_of_birth``. While either column might be useful for making features, the ``join_date`` should be used as the time index because it indicates when that customer first became available in the dataset.\n",
    "\n",
    ".. important::\n",
    "\n",
    "    The **time index** is defined as the first time that any information from a row can be used. If a cutoff time is specified when calculating features, rows that have a later value for the time index are automatically ignored.\n",
    "\n",
    ".. _cutoff-time:\n",
    "\n",
    "What is the Cutoff Time?\n",
    "------------------------\n",
    "The **cutoff_time** specifies the last point in time that a row’s data can be used for a feature calculation. Any data after this point in time will be filtered out before calculating features.\n",
    "\n",
    "For example, let's consider a dataset of timestamped customer transactions, where we want to predict whether customers ``1``, ``2`` and ``3`` will spend $500 between ``04:00`` on January 1 and the end of the day. When building features for this prediction problem, we need to ensure that no data after ``04:00`` is used in our calculations.\n",
    "\n",
    ".. image:: ../_static/images/retail_ct.png\n",
    "   :width: 400 px\n",
    "   :alt: retail cutoff time diagram\n",
    "   :align: center\n",
    "\n",
    "We pass the cutoff time to :func:`featuretools.dfs` or :func:`featuretools.calculate_feature_matrix` using the ``cutoff_time`` argument like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f3050282",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'IdentityFeature' object has no attribute 'entity'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-3d8eb46d682f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m fm, features = ft.dfs(entityset=es,\n\u001b[0m\u001b[1;32m      2\u001b[0m                       \u001b[0mtarget_dataframe_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'customers'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                       \u001b[0mcutoff_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"2014-1-1 04:00\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                       \u001b[0minstance_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                       cutoff_time_in_index=True)\n",
      "\u001b[0;32m~/repositories/featuretools/featuretools/utils/entry_point.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m                     ep.on_error(error=e,\n\u001b[1;32m     39\u001b[0m                                 runtime=runtime)\n\u001b[0;32m---> 40\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;31m# send return value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repositories/featuretools/featuretools/utils/entry_point.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0;31m# call function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                 \u001b[0mreturn_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m                 \u001b[0mruntime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repositories/featuretools/featuretools/synthesis/dfs.py\u001b[0m in \u001b[0;36mdfs\u001b[0;34m(dataframes, relationships, entityset, target_dataframe_name, cutoff_time, instance_ids, agg_primitives, trans_primitives, groupby_trans_primitives, allowed_paths, max_depth, ignore_dataframes, ignore_columns, primitive_options, seed_features, drop_contains, drop_exact, where_primitives, max_features, cutoff_time_in_index, save_progress, features_only, training_window, approximate, chunk_size, n_jobs, dask_kwargs, verbose, return_types, progress_callback, include_cutoff_time)\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m     feature_matrix = calculate_feature_matrix(features,\n\u001b[0m\u001b[1;32m    281\u001b[0m                                               \u001b[0mentityset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mentityset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m                                               \u001b[0mcutoff_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcutoff_time\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repositories/featuretools/featuretools/computational_backends/calculate_feature_matrix.py\u001b[0m in \u001b[0;36mcalculate_feature_matrix\u001b[0;34m(features, entityset, cutoff_time, instance_ids, entities, relationships, cutoff_time_in_index, training_window, approximate, save_progress, verbose, chunk_size, n_jobs, dask_kwargs, progress_callback, include_cutoff_time)\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m     \u001b[0mtarget_dataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentityset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0mcutoff_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_cutoff_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcutoff_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_dataframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'IdentityFeature' object has no attribute 'entity'"
     ]
    }
   ],
   "source": [
    "fm, features = ft.dfs(entityset=es,\n",
    "                      target_dataframe_name='customers',\n",
    "                      cutoff_time=pd.Timestamp(\"2014-1-1 04:00\"),\n",
    "                      instance_ids=[1,2,3],\n",
    "                      cutoff_time_in_index=True)\n",
    "fm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61c51cd",
   "metadata": {},
   "source": [
    "Even though the entityset contains the complete transaction history for each customer, only data with a time index up to and including the cutoff time was used to calculate the features above.\n",
    "\n",
    "Using a Cutoff Time DataFrame\n",
    "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "Oftentimes, the training examples for machine learning will come from different points in time. To specify a unique cutoff time for each row of the resulting feature matrix, we can pass a dataframe which includes one column for the instance id and another column for the corresponding cutoff time. These columns can be in any order, but they must be named properly. The column with the instance ids must either be named ``instance_id`` or have the same name as the target dataframe ``index``. The column with the cutoff time values must either be named ``time`` or have the same name as the target dataframe ``time_index``.\n",
    "\n",
    "The column names for the instance ids and the cutoff time values should be unambiguous. Passing a dataframe that contains both a column with the same name as the target dataframe ``index`` and a column named ``instance_id`` will result in an error. Similarly, if the cutoff time dataframe contains both a column with the same name as the target dataframe ``time_index`` and a column named ``time`` an error will be raised.\n",
    "\n",
    ".. note::\n",
    "\n",
    "    Only the columns corresponding to the instance ids and the cutoff times are used to calculate features. Any additional columns passed through are appended to the resulting feature matrix. This is typically used to pass through machine learning labels to ensure that they stay aligned with the feature matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2e16daa7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'IdentityFeature' object has no attribute 'entity'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-5feb4f9541e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mcutoff_times\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mcutoff_times\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m fm, features = ft.dfs(entityset=es,\n\u001b[0m\u001b[1;32m     10\u001b[0m                       \u001b[0mtarget_dataframe_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'customers'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                       \u001b[0mcutoff_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcutoff_times\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repositories/featuretools/featuretools/utils/entry_point.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m                     ep.on_error(error=e,\n\u001b[1;32m     39\u001b[0m                                 runtime=runtime)\n\u001b[0;32m---> 40\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;31m# send return value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repositories/featuretools/featuretools/utils/entry_point.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0;31m# call function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                 \u001b[0mreturn_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m                 \u001b[0mruntime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repositories/featuretools/featuretools/synthesis/dfs.py\u001b[0m in \u001b[0;36mdfs\u001b[0;34m(dataframes, relationships, entityset, target_dataframe_name, cutoff_time, instance_ids, agg_primitives, trans_primitives, groupby_trans_primitives, allowed_paths, max_depth, ignore_dataframes, ignore_columns, primitive_options, seed_features, drop_contains, drop_exact, where_primitives, max_features, cutoff_time_in_index, save_progress, features_only, training_window, approximate, chunk_size, n_jobs, dask_kwargs, verbose, return_types, progress_callback, include_cutoff_time)\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m     feature_matrix = calculate_feature_matrix(features,\n\u001b[0m\u001b[1;32m    281\u001b[0m                                               \u001b[0mentityset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mentityset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m                                               \u001b[0mcutoff_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcutoff_time\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repositories/featuretools/featuretools/computational_backends/calculate_feature_matrix.py\u001b[0m in \u001b[0;36mcalculate_feature_matrix\u001b[0;34m(features, entityset, cutoff_time, instance_ids, entities, relationships, cutoff_time_in_index, training_window, approximate, save_progress, verbose, chunk_size, n_jobs, dask_kwargs, progress_callback, include_cutoff_time)\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m     \u001b[0mtarget_dataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentityset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0mcutoff_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_cutoff_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcutoff_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_dataframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'IdentityFeature' object has no attribute 'entity'"
     ]
    }
   ],
   "source": [
    "cutoff_times = pd.DataFrame()\n",
    "cutoff_times['customer_id'] = [1, 2, 3, 1]\n",
    "cutoff_times['time'] = pd.to_datetime(['2014-1-1 04:00',\n",
    "                             '2014-1-1 05:00',\n",
    "                             '2014-1-1 06:00',\n",
    "                             '2014-1-1 08:00'])\n",
    "cutoff_times['label'] = [True, True, False, True]\n",
    "cutoff_times\n",
    "fm, features = ft.dfs(entityset=es,\n",
    "                      target_dataframe_name='customers',\n",
    "                      cutoff_time=cutoff_times,\n",
    "                      cutoff_time_in_index=True)\n",
    "fm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01384f81",
   "metadata": {},
   "source": [
    "We can now see that every row of the feature matrix is calculated at the corresponding time in the cutoff time dataframe. Because we calculate each row at a different time, it is possible to have a repeat customer. In this case, we calculated the feature vector for customer 1 at both ``04:00`` and ``08:00``.\n",
    "\n",
    "Training Window\n",
    "---------------\n",
    "\n",
    "By default, all data up to and including the cutoff time is used. We can restrict the amount of historical data that is selected for calculations using a \"training window.\"\n",
    "\n",
    "Here's an example of using a two hour training window:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8ad84692",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'IdentityFeature' object has no attribute 'entity'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-c8355bba636d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m window_fm, window_features = ft.dfs(entityset=es,\n\u001b[0m\u001b[1;32m      2\u001b[0m                                     \u001b[0mtarget_dataframe_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"customers\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                     \u001b[0mcutoff_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcutoff_times\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                     \u001b[0mcutoff_time_in_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                     training_window=\"2 hour\")\n",
      "\u001b[0;32m~/repositories/featuretools/featuretools/utils/entry_point.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m                     ep.on_error(error=e,\n\u001b[1;32m     39\u001b[0m                                 runtime=runtime)\n\u001b[0;32m---> 40\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;31m# send return value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repositories/featuretools/featuretools/utils/entry_point.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0;31m# call function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                 \u001b[0mreturn_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m                 \u001b[0mruntime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repositories/featuretools/featuretools/synthesis/dfs.py\u001b[0m in \u001b[0;36mdfs\u001b[0;34m(dataframes, relationships, entityset, target_dataframe_name, cutoff_time, instance_ids, agg_primitives, trans_primitives, groupby_trans_primitives, allowed_paths, max_depth, ignore_dataframes, ignore_columns, primitive_options, seed_features, drop_contains, drop_exact, where_primitives, max_features, cutoff_time_in_index, save_progress, features_only, training_window, approximate, chunk_size, n_jobs, dask_kwargs, verbose, return_types, progress_callback, include_cutoff_time)\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m     feature_matrix = calculate_feature_matrix(features,\n\u001b[0m\u001b[1;32m    281\u001b[0m                                               \u001b[0mentityset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mentityset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m                                               \u001b[0mcutoff_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcutoff_time\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repositories/featuretools/featuretools/computational_backends/calculate_feature_matrix.py\u001b[0m in \u001b[0;36mcalculate_feature_matrix\u001b[0;34m(features, entityset, cutoff_time, instance_ids, entities, relationships, cutoff_time_in_index, training_window, approximate, save_progress, verbose, chunk_size, n_jobs, dask_kwargs, progress_callback, include_cutoff_time)\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m     \u001b[0mtarget_dataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentityset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0mcutoff_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_cutoff_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcutoff_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_dataframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'IdentityFeature' object has no attribute 'entity'"
     ]
    }
   ],
   "source": [
    "window_fm, window_features = ft.dfs(entityset=es,\n",
    "                                    target_dataframe_name=\"customers\",\n",
    "                                    cutoff_time=cutoff_times,\n",
    "                                    cutoff_time_in_index=True,\n",
    "                                    training_window=\"2 hour\")\n",
    "\n",
    "window_fm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef341c5",
   "metadata": {},
   "source": [
    "We can see that that the counts for the same feature are lower after we shorten the training window:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "046401bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1   2014-01-01 00:16:15\n",
       "2   2014-01-01 00:27:05\n",
       "3   2014-01-01 00:43:20\n",
       "4   2014-01-01 01:10:25\n",
       "5   2014-01-01 01:22:20\n",
       "Name: _ft_last_time, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_time_index_col = es['sessions'].ww.metadata.get('last_time_index')\n",
    "es['sessions']['session_start'].head()\n",
    "es['sessions'][last_time_index_col].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52981c43",
   "metadata": {},
   "source": [
    "Featuretools can automatically add last time indexes to every :class:`Entity` in an :class:`Entityset` by running ``EntitySet.add_last_time_indexes()``. If a ``last_time_index`` has been set, Featuretools will check to see if the ``last_time_index`` is after the start of the training window. That, combined with the cutoff time, allows DFS to discover which data is relevant for a given training window.\n",
    "\n",
    "\n",
    "Excluding data at cutoff times\n",
    "-----------------------------------------------\n",
    "The ``cutoff_time`` is the last point in time where data can be used for feature\n",
    "calculation. If you don't want to use the data at the cutoff time in feature\n",
    "calculation, you can exclude that data by setting ``include_cutoff_time`` to\n",
    "``False`` in :func:`featuretools.dfs` or:func:`featuretools.calculate_feature_matrix`.\n",
    "If you set it to ``True`` (the default behavior), data from the cutoff time point\n",
    "will be used.\n",
    "\n",
    "Setting ``include_cutoff_time`` to ``False`` also impacts how data at the edges\n",
    "of training windows are included or excluded.  Take this slice of data as an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b52807f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>session_id</th>\n",
       "      <th>transaction_time</th>\n",
       "      <th>product_id</th>\n",
       "      <th>amount</th>\n",
       "      <th>_ft_last_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>298</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-01-01 00:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>127.64</td>\n",
       "      <td>2014-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-01-01 00:01:05</td>\n",
       "      <td>2</td>\n",
       "      <td>109.48</td>\n",
       "      <td>2014-01-01 00:01:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>308</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-01-01 00:02:10</td>\n",
       "      <td>3</td>\n",
       "      <td>95.06</td>\n",
       "      <td>2014-01-01 00:02:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>116</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-01-01 00:03:15</td>\n",
       "      <td>4</td>\n",
       "      <td>78.92</td>\n",
       "      <td>2014-01-01 00:03:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>371</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-01-01 00:04:20</td>\n",
       "      <td>3</td>\n",
       "      <td>31.54</td>\n",
       "      <td>2014-01-01 00:04:20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     transaction_id  session_id    transaction_time product_id  amount  \\\n",
       "298             298           1 2014-01-01 00:00:00          5  127.64   \n",
       "2                 2           1 2014-01-01 00:01:05          2  109.48   \n",
       "308             308           1 2014-01-01 00:02:10          3   95.06   \n",
       "116             116           1 2014-01-01 00:03:15          4   78.92   \n",
       "371             371           1 2014-01-01 00:04:20          3   31.54   \n",
       "\n",
       "          _ft_last_time  \n",
       "298 2014-01-01 00:00:00  \n",
       "2   2014-01-01 00:01:05  \n",
       "308 2014-01-01 00:02:10  \n",
       "116 2014-01-01 00:03:15  \n",
       "371 2014-01-01 00:04:20  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.add_last_time_indexes()\n",
    "\n",
    "df = es['transactions']\n",
    "df[df[\"session_id\"] == 1].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851385aa",
   "metadata": {},
   "source": [
    "Looking at the data, transactions occur every 65 seconds.  To check how ``include_cutoff_time``\n",
    "effects training windows, we can calculate features at the time of a transaction\n",
    "while using a 65 second training window.  This creates a training window with a\n",
    "transaction at both endpoints of the window.  For this example, we'll find the sum\n",
    "of all transactions for session id 1 that are in the training window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ebd2596d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__new__() got an unexpected keyword argument 'parent_entity'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-c6353f6f403e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfeaturetools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimitives\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m sum_log = ft.Feature(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mbase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'transactions'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'amount'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mparent_entity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sessions'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __new__() got an unexpected keyword argument 'parent_entity'"
     ]
    }
   ],
   "source": [
    "from featuretools.primitives import Sum\n",
    "\n",
    "sum_log = ft.Feature(\n",
    "    base=es['transactions']['amount'],\n",
    "    parent_entity=es['sessions'],\n",
    "    primitive=Sum,\n",
    ")\n",
    "cutoff_time = pd.DataFrame({\n",
    "    'session_id': [1],\n",
    "    'time': ['2014-01-01 00:04:20'],\n",
    "}).astype({'time': 'datetime64[ns]'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ed885a",
   "metadata": {},
   "source": [
    "With ``include_cutoff_time=True``, the oldest point in the training window\n",
    "(``2014-01-01 00:03:15``) is excluded and the cutoff time point is included. This\n",
    "means only transaction 371 is in the training window, so the sum of all transaction\n",
    "amounts is 31.54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "283a14ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sum_log' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-ce18c023d711>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Case1. include_cutoff_time = True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m actual = ft.calculate_feature_matrix(\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msum_log\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mentityset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcutoff_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcutoff_time\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sum_log' is not defined"
     ]
    }
   ],
   "source": [
    "# Case1. include_cutoff_time = True\n",
    "actual = ft.calculate_feature_matrix(\n",
    "    features=[sum_log],\n",
    "    entityset=es,\n",
    "    cutoff_time=cutoff_time,\n",
    "    cutoff_time_in_index=True,\n",
    "    training_window='65 seconds',\n",
    "    include_cutoff_time=True,\n",
    ")\n",
    "actual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca78f4f",
   "metadata": {},
   "source": [
    "Whereas with ``include_cutoff_time=False``, the oldest point in the window is\n",
    "included and the cutoff time point is excluded.  So in this case transaction 116\n",
    "is included and transaction 371 is exluded, and the sum is 78.92\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "42bc84a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sum_log' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-b6781361936e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Case2. include_cutoff_time = False\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m actual = ft.calculate_feature_matrix(\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msum_log\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mentityset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcutoff_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcutoff_time\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sum_log' is not defined"
     ]
    }
   ],
   "source": [
    "# Case2. include_cutoff_time = False\n",
    "actual = ft.calculate_feature_matrix(\n",
    "    features=[sum_log],\n",
    "    entityset=es,\n",
    "    cutoff_time=cutoff_time,\n",
    "    cutoff_time_in_index=True,\n",
    "    training_window='65 seconds',\n",
    "    include_cutoff_time=False,\n",
    ")\n",
    "actual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1045da46",
   "metadata": {},
   "source": [
    "\n",
    ".. _approximate:\n",
    "\n",
    "Approximating Features by Rounding Cutoff Times\n",
    "-----------------------------------------------\n",
    "\n",
    "For each unique cutoff time, Featuretools must perform operations to select the data that’s valid for computations. If there are a large number of unique cutoff times relative to the number of instances for which we are calculating features, the time spent filtering data can add up. By reducing the number of unique cutoff times, we minimize the overhead from searching for and extracting data for feature calculations.\n",
    "\n",
    "One way to decrease the number of unique cutoff times is to round cutoff times to an earlier point in time. An earlier cutoff time is always valid for predictive modeling — it just means we’re not using some of the data we could potentially use while calculating that feature. So, we gain computational speed by losing a small amount of information.\n",
    "\n",
    "To understand when an approximation is useful, consider calculating features for a model to predict fraudulent credit card transactions. In this case, an important feature might be, \"the average transaction amount for this card in the past\". While this value can change every time there is a new transaction, updating it less frequently might not impact accuracy.\n",
    "\n",
    ".. note::\n",
    "\n",
    "    The bank BBVA used approximation when building a predictive model for credit card fraud using Featuretools. For more details, see the \"Real-time deployment considerations\" section of the `white paper <https://arxiv.org/pdf/1710.07709.pdf>`_ describing the work involved.\n",
    "\n",
    "The frequency of approximation is controlled using the ``approximate`` parameter to :func:`featuretools.dfs` or :func:`featuretools.calculate_feature_matrix`. For example, the following code would approximate aggregation features at 1 day intervals::\n",
    "\n",
    "    fm = ft.calculate_feature_matrix(features=features,\n",
    "                                     entityset=es_transactions,\n",
    "                                     cutoff_time=ct_transactions,\n",
    "                                     approximate=\"1 day\")\n",
    "\n",
    "In this computation, features that can be approximated will be calculated at 1 day intervals, while features that cannot be approximated (e.g \"what is the destination of this flight?\") will be calculated at the exact cutoff time.\n",
    "\n",
    "\n",
    ".. _secondary-time-index:\n",
    "\n",
    "Secondary Time Index\n",
    "--------------------\n",
    "\n",
    "It is sometimes the case that information in a dataset is updated or added after a row has been created. This means that certain columns may actually become known after the time index for a row. Rather than drop those columns to avoid leaking information, we can create a secondary time index to indicate when those columns become known.\n",
    "\n",
    "The :func:`Flights <demo.load_flight>` entityset is a good example of a dataset where column values in a row become known at different times. Each trip is recorded in the ``trip_logs`` entity, and has many times associated with it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "80296a45",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-43-937c58ab3aa1>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-43-937c58ab3aa1>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    :suppress:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    ":suppress:\n",
    "\n",
    "import urllib.request as urllib2\n",
    "opener = urllib2.build_opener()\n",
    "opener.addheaders = [('Testing', 'True')]\n",
    "urllib2.install_opener(opener)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d2b44706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_log_id</th>\n",
       "      <th>flight_id</th>\n",
       "      <th>date_scheduled</th>\n",
       "      <th>scheduled_dep_time</th>\n",
       "      <th>scheduled_arr_time</th>\n",
       "      <th>dep_time</th>\n",
       "      <th>arr_time</th>\n",
       "      <th>dep_delay</th>\n",
       "      <th>taxi_out</th>\n",
       "      <th>taxi_in</th>\n",
       "      <th>arr_delay</th>\n",
       "      <th>diverted</th>\n",
       "      <th>scheduled_elapsed_time</th>\n",
       "      <th>air_time</th>\n",
       "      <th>distance</th>\n",
       "      <th>carrier_delay</th>\n",
       "      <th>weather_delay</th>\n",
       "      <th>national_airspace_delay</th>\n",
       "      <th>security_delay</th>\n",
       "      <th>late_aircraft_delay</th>\n",
       "      <th>canceled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>AA-494:RSW-&gt;CLT</td>\n",
       "      <td>2016-09-03</td>\n",
       "      <td>2017-01-01 13:14:00</td>\n",
       "      <td>2017-01-01 15:05:00</td>\n",
       "      <td>2017-01-01 13:03:00</td>\n",
       "      <td>2017-01-01 14:53:00</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0 days 01:51:00</td>\n",
       "      <td>88.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>AA-495:ATL-&gt;PHX</td>\n",
       "      <td>2016-09-03</td>\n",
       "      <td>2017-01-01 11:30:00</td>\n",
       "      <td>2017-01-01 15:40:00</td>\n",
       "      <td>2017-01-01 11:24:00</td>\n",
       "      <td>2017-01-01 15:41:00</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0 days 04:10:00</td>\n",
       "      <td>224.0</td>\n",
       "      <td>1587.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>AA-495:CLT-&gt;ATL</td>\n",
       "      <td>2016-09-03</td>\n",
       "      <td>2017-01-01 09:25:00</td>\n",
       "      <td>2017-01-01 10:42:00</td>\n",
       "      <td>2017-01-01 09:23:00</td>\n",
       "      <td>2017-01-01 10:39:00</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0 days 01:17:00</td>\n",
       "      <td>50.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    trip_log_id        flight_id date_scheduled  scheduled_dep_time  \\\n",
       "30           30  AA-494:RSW->CLT     2016-09-03 2017-01-01 13:14:00   \n",
       "38           38  AA-495:ATL->PHX     2016-09-03 2017-01-01 11:30:00   \n",
       "46           46  AA-495:CLT->ATL     2016-09-03 2017-01-01 09:25:00   \n",
       "\n",
       "    scheduled_arr_time            dep_time            arr_time  dep_delay  \\\n",
       "30 2017-01-01 15:05:00 2017-01-01 13:03:00 2017-01-01 14:53:00      -11.0   \n",
       "38 2017-01-01 15:40:00 2017-01-01 11:24:00 2017-01-01 15:41:00       -6.0   \n",
       "46 2017-01-01 10:42:00 2017-01-01 09:23:00 2017-01-01 10:39:00       -2.0   \n",
       "\n",
       "    taxi_out  taxi_in  arr_delay  diverted scheduled_elapsed_time  air_time  \\\n",
       "30      12.0     10.0      -12.0     False        0 days 01:51:00      88.0   \n",
       "38      28.0      5.0        1.0     False        0 days 04:10:00     224.0   \n",
       "46      18.0      8.0       -3.0     False        0 days 01:17:00      50.0   \n",
       "\n",
       "    distance  carrier_delay  weather_delay  national_airspace_delay  \\\n",
       "30     600.0            0.0            0.0                      0.0   \n",
       "38    1587.0            0.0            0.0                      0.0   \n",
       "46     226.0            0.0            0.0                      0.0   \n",
       "\n",
       "    security_delay  late_aircraft_delay  canceled  \n",
       "30             0.0                  0.0     False  \n",
       "38             0.0                  0.0     False  \n",
       "46             0.0                  0.0     False  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_flight = ft.demo.load_flight(nrows=100)\n",
    "es_flight\n",
    "es_flight['trip_logs'].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6108dd31",
   "metadata": {},
   "source": [
    "For every trip log, the time index is ``date_scheduled``, which is when the airline decided on the scheduled departure and arrival times, as well as what route will be flown. We don't know the rest of the information about the actual departure/arrival times and the details of any delay at this time. However, it is possible to know everything about how a trip went after it has arrived, so we can use that information at any time after the flight lands.\n",
    "\n",
    "Using a secondary time index, we can indicate to Featuretools which columns in our flight logs are known at the time the flight is scheduled, plus which are known at the time the flight lands.\n",
    "\n",
    "\n",
    ".. image:: ../_static/images/flight_ti_2.png\n",
    "   :width: 400 px\n",
    "   :alt: flight secondary time index diagram\n",
    "   :align: center\n",
    "\n",
    "In Featuretools, when creating the entity, we set the secondary time index to be the arrival time like this::\n",
    "\n",
    "    es = ft.EntitySet('Flight Data')\n",
    "    arr_time_columns = ['arr_delay', 'dep_delay', 'carrier_delay', 'weather_delay',\n",
    "                        'national_airspace_delay', 'security_delay',\n",
    "                        'late_aircraft_delay', 'canceled', 'diverted',\n",
    "                        'taxi_in', 'taxi_out', 'air_time', 'dep_time']\n",
    "\n",
    "    es.add_dataframe(\n",
    "        dataframe_name='trip_logs',\n",
    "        dataframe=data,\n",
    "        index='trip_log_id',\n",
    "        make_index=True,\n",
    "        time_index='date_scheduled',\n",
    "        secondary_time_index={'arr_time': arr_time_columns})\n",
    "\n",
    "By setting a secondary time index, we can still use the delay information from a row, but only when it becomes known.\n",
    "\n",
    ".. hint::\n",
    "\n",
    "    It's often a good idea to use a secondary time index if your entityset has inline labels. If you know when the label would be valid for use, it's possible to automatically create very predictive features using historical labels.\n",
    "\n",
    ".. _flight-ct:\n",
    "\n",
    "Flight Predictions\n",
    "~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "Let's make some features at varying times using the flight example described above. Trip ``14`` is a flight from CLT to PHX on January 31, 2017 and trip ``92`` is a flight from PIT to DFW on January 1. We can set any cutoff time before the flight is scheduled to depart, emulating how we would make the prediction at that point in time.\n",
    "\n",
    "We set two cutoff times for trip ``14`` at two different times: one which is more than a month before the flight and another which is only 5 days before. For trip ``92``, we'll only set one cutoff time, three days before it is scheduled to leave.\n",
    "\n",
    ".. image:: ../_static/images/flight_ct.png\n",
    "   :width: 500 px\n",
    "   :alt: flight cutoff time diagram\n",
    "   :align: center\n",
    "\n",
    "Our cutoff time dataframe looks like this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4d08569f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_log_id</th>\n",
       "      <th>time</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14</td>\n",
       "      <td>2016-12-28</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>2017-01-25</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92</td>\n",
       "      <td>2016-12-28</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   trip_log_id       time  label\n",
       "0           14 2016-12-28   True\n",
       "1           14 2017-01-25   True\n",
       "2           92 2016-12-28  False"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct_flight = pd.DataFrame()\n",
    "ct_flight['trip_log_id'] = [14, 14, 92]\n",
    "ct_flight['time'] = pd.to_datetime(['2016-12-28',\n",
    "                                    '2017-1-25',\n",
    "                                    '2016-12-28'])\n",
    "ct_flight['label'] = [True, True, False]\n",
    "ct_flight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2227c6a1",
   "metadata": {},
   "source": [
    "Now, let's calculate the feature matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "545483af",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'IdentityFeature' object has no attribute 'entity'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-270753bd3212>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m fm, features = ft.dfs(entityset=es_flight,\n\u001b[0m\u001b[1;32m      2\u001b[0m                       \u001b[0mtarget_dataframe_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'trip_logs'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                       \u001b[0mcutoff_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mct_flight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                       \u001b[0mcutoff_time_in_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                       \u001b[0magg_primitives\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"max\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repositories/featuretools/featuretools/utils/entry_point.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m                     ep.on_error(error=e,\n\u001b[1;32m     39\u001b[0m                                 runtime=runtime)\n\u001b[0;32m---> 40\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;31m# send return value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repositories/featuretools/featuretools/utils/entry_point.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0;31m# call function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                 \u001b[0mreturn_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m                 \u001b[0mruntime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repositories/featuretools/featuretools/synthesis/dfs.py\u001b[0m in \u001b[0;36mdfs\u001b[0;34m(dataframes, relationships, entityset, target_dataframe_name, cutoff_time, instance_ids, agg_primitives, trans_primitives, groupby_trans_primitives, allowed_paths, max_depth, ignore_dataframes, ignore_columns, primitive_options, seed_features, drop_contains, drop_exact, where_primitives, max_features, cutoff_time_in_index, save_progress, features_only, training_window, approximate, chunk_size, n_jobs, dask_kwargs, verbose, return_types, progress_callback, include_cutoff_time)\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m     feature_matrix = calculate_feature_matrix(features,\n\u001b[0m\u001b[1;32m    281\u001b[0m                                               \u001b[0mentityset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mentityset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m                                               \u001b[0mcutoff_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcutoff_time\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repositories/featuretools/featuretools/computational_backends/calculate_feature_matrix.py\u001b[0m in \u001b[0;36mcalculate_feature_matrix\u001b[0;34m(features, entityset, cutoff_time, instance_ids, entities, relationships, cutoff_time_in_index, training_window, approximate, save_progress, verbose, chunk_size, n_jobs, dask_kwargs, progress_callback, include_cutoff_time)\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m     \u001b[0mtarget_dataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentityset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0mcutoff_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_cutoff_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcutoff_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_dataframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'IdentityFeature' object has no attribute 'entity'"
     ]
    }
   ],
   "source": [
    "fm, features = ft.dfs(entityset=es_flight,\n",
    "                      target_dataframe_name='trip_logs',\n",
    "                      cutoff_time=ct_flight,\n",
    "                      cutoff_time_in_index=True,\n",
    "                      agg_primitives=[\"max\"],\n",
    "                      trans_primitives=[\"month\"],)\n",
    "fm[['flight_id', 'label', 'flights.MAX(trip_logs.arr_delay)', 'MONTH(scheduled_dep_time)']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757b7f9e",
   "metadata": {},
   "source": [
    "\n",
    "Let's understand the output:\n",
    "\n",
    "1. A row was made for every id-time pair in ``ct_flight``, which is returned as the index of the feature matrix.\n",
    "\n",
    "2. The output was sorted by cutoff time. Because of the sorting, it's often helpful to pass in a label with the cutoff time dataframe so that it will remain sorted in the same fashion as the feature matrix. Any additional columns beyond ``id`` and ``cutoff_time`` will not be used for making features.\n",
    "\n",
    "3. The column ``flights.MAX(trip_logs.arr_delay)`` is not always defined. It can only have any real values when there are historical flights to aggregate. Notice that, for trip ``14``, there wasn't any historical data when we made the feature a month in advance, but there **were** flights to aggregate when we shortened it to 5 days. These are powerful features that are often excluded in manual processes because of how hard they are to make.\n",
    "\n",
    "\n",
    "Creating and Flattening a Feature Tensor\n",
    "----------------------------------------\n",
    "\n",
    "The :func:`make_temporal_cutoffs` function generates a series of equally spaced cutoff times from a given set of cutoff times and instance ids.\n",
    "\n",
    "This function can be paired with DFS to create and flatten a feature tensor rather than making multiple feature matrices at different delays.\n",
    "\n",
    "The function\n",
    "takes in the the following parameters:\n",
    "\n",
    " * ``instance_ids (list, pd.Series, or np.ndarray)``: A list of instances.\n",
    " * ``cutoffs (list, pd.Series, or np.ndarray)``: An associated list of cutoff times.\n",
    " * ``window_size (str or pandas.DateOffset)``: The amount of time between each cutoff time in the created time series.\n",
    " * ``start (datetime.datetime or pd.Timestamp)``: The first cutoff time in the created time series.\n",
    " * ``num_windows (int)``: The number of cutoff times to create in the created time series.\n",
    "\n",
    "Only two of the three options ``window_size``, ``start``, and ``num_windows`` need to be specified to uniquely determine an equally-spaced set of cutoff times at which to compute each instance.\n",
    "\n",
    "If your cutoff times are the ones used above:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc9351b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94341bb1",
   "metadata": {},
   "source": [
    "Then passing in ``window_size='1h'`` and ``num_windows=2`` makes one row an hour over the last two hours to produce the following new dataframe. The result can be directly passed into DFS to make features at the different time points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d6281f59",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'IdentityFeature' object has no attribute 'entity'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-507347b1b015>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                             num_windows=2)\n\u001b[1;32m      5\u001b[0m \u001b[0mtemporal_cutoffs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m fm, features = ft.dfs(entityset=es,\n\u001b[0m\u001b[1;32m      7\u001b[0m                       \u001b[0mtarget_dataframe_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'customers'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                       \u001b[0mcutoff_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtemporal_cutoffs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repositories/featuretools/featuretools/utils/entry_point.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m                     ep.on_error(error=e,\n\u001b[1;32m     39\u001b[0m                                 runtime=runtime)\n\u001b[0;32m---> 40\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;31m# send return value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repositories/featuretools/featuretools/utils/entry_point.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0;31m# call function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                 \u001b[0mreturn_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m                 \u001b[0mruntime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repositories/featuretools/featuretools/synthesis/dfs.py\u001b[0m in \u001b[0;36mdfs\u001b[0;34m(dataframes, relationships, entityset, target_dataframe_name, cutoff_time, instance_ids, agg_primitives, trans_primitives, groupby_trans_primitives, allowed_paths, max_depth, ignore_dataframes, ignore_columns, primitive_options, seed_features, drop_contains, drop_exact, where_primitives, max_features, cutoff_time_in_index, save_progress, features_only, training_window, approximate, chunk_size, n_jobs, dask_kwargs, verbose, return_types, progress_callback, include_cutoff_time)\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m     feature_matrix = calculate_feature_matrix(features,\n\u001b[0m\u001b[1;32m    281\u001b[0m                                               \u001b[0mentityset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mentityset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m                                               \u001b[0mcutoff_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcutoff_time\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repositories/featuretools/featuretools/computational_backends/calculate_feature_matrix.py\u001b[0m in \u001b[0;36mcalculate_feature_matrix\u001b[0;34m(features, entityset, cutoff_time, instance_ids, entities, relationships, cutoff_time_in_index, training_window, approximate, save_progress, verbose, chunk_size, n_jobs, dask_kwargs, progress_callback, include_cutoff_time)\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m     \u001b[0mtarget_dataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentityset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0mcutoff_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_cutoff_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcutoff_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_dataframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'IdentityFeature' object has no attribute 'entity'"
     ]
    }
   ],
   "source": [
    "temporal_cutoffs = ft.make_temporal_cutoffs(cutoff_times['customer_id'],\n",
    "                                            cutoff_times['time'],\n",
    "                                            window_size='1h',\n",
    "                                            num_windows=2)\n",
    "temporal_cutoffs\n",
    "fm, features = ft.dfs(entityset=es,\n",
    "                      target_dataframe_name='customers',\n",
    "                      cutoff_time=temporal_cutoffs,\n",
    "                      cutoff_time_in_index=True)\n",
    "fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6518ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
