{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Representing Data with EntitySets\n",
    "\n",
    "An ``EntitySet`` is a collection of entities and the relationships between them. They are useful for preparing raw, structured datasets for feature engineering. While many functions in Featuretools  take ``entities`` and ``relationships`` as separate arguments, it is recommended to create an ``EntitySet``, so you can more easily manipulate your data as needed.\n",
    "\n",
    "## The Raw Data\n",
    "\n",
    "Below we have a two tables of data (represented as Pandas DataFrames) related to customer transactions. The first is a merge of transactions, sessions, and customers so that the result looks like something you might see in a log file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import featuretools as ft\n",
    "data = ft.demo.load_mock_customer()\n",
    "transactions_df = data[\"transactions\"].merge(data[\"sessions\"]).merge(data[\"customers\"])\n",
    "\n",
    "transactions_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the second dataframe is a list of products involved in those transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_df = data[\"products\"]\n",
    "products_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an EntitySet\n",
    "\n",
    "First, we initialize an EntitySet. If you'd like to give it name, you can optionally provide an ``id`` to the constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = ft.EntitySet(id=\"customer_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding entities\n",
    "\n",
    "To get started, we load the transactions dataframe as an entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from woodwork.logical_types import Categorical, PostalCode\n",
    "\n",
    "es = es.add_dataframe(\n",
    "    dataframe_name=\"transactions\",\n",
    "    dataframe=transactions_df,\n",
    "    index=\"transaction_id\",\n",
    "    time_index=\"transaction_time\",\n",
    "    logical_types={\n",
    "        \"product_id\": ww.logical_types.Categorical,\n",
    "        \"zip_code\": ww.logical_types.PostalCode,\n",
    "    },\n",
    ")\n",
    "\n",
    "es"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    ".. currentmodule:: featuretools\n",
    "\n",
    ".. note ::\n",
    "\n",
    "    You can also display your entity set structure graphically by calling :meth:`.EntitySet.plot`.\n",
    "\n",
    "This method loads each column in the dataframe in as a variable. We can see the variables in an entity using the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es[\"transactions\"].variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the call to ``add_dataframe``, we specified three important parameters\n",
    "\n",
    "* The ``index`` parameter specifies the column that uniquely identifies rows in the dataframe\n",
    "* The ``time_index`` parameter tells Featuretools when the data was created.\n",
    "* The ``logical_types`` parameter indicates that \"product_id\" should be interpreted as a Categorical variable, even though it just an integer in the underlying data.\n",
    "\n",
    "Now, we can do that same thing with our products dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = es.add_dataframe(\n",
    "    dataframe_name=\"products\",\n",
    "    dataframe=products_df,\n",
    "    index=\"product_id\")\n",
    "\n",
    "es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With two entities in our entity set, we can add a relationship between them.\n",
    "\n",
    "## Adding a Relationship\n",
    "\n",
    "We want to relate these two entities by the columns called \"product_id\" in each entity. Each product has multiple transactions associated with it, so it is called it the **parent entity**, while the transactions entity is known as the **child entity**. When specifying relationships we list the variable in the parent entity first. Note that each `ft.Relationship` must denote a one-to-many relationship rather than a relationship which is one-to-one or many-to-many."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = es.add_relationship(\"products\", \"product_id\", \"transactions\", \"product_id\")\n",
    "es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we see the relationship has been added to our entity set.\n",
    "\n",
    "## Creating entity from existing table\n",
    "\n",
    "When working with raw data, it is common to have sufficient information to justify the creation of new entities. In order to create a new entity and relationship for sessions, we \"normalize\" the transaction entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = es.normalize_dataframe(\n",
    "    base_dataframe_name=\"transactions\",\n",
    "    new_dataframe_name=\"sessions\",\n",
    "    index=\"session_id\",\n",
    "    make_time_index=\"session_start\",\n",
    "    additional_columns=[\n",
    "        \"device\",\n",
    "        \"customer_id\",\n",
    "        \"zip_code\",\n",
    "        \"session_start\",\n",
    "        \"join_date\",\n",
    "    ],\n",
    ")\n",
    "es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the output above, we see this method did two operations\n",
    "\n",
    "1. It created a new entity called \"sessions\" based on the \"session_id\" and \"session_start\" variables in \"transactions\"\n",
    "2. It added a relationship connecting \"transactions\" and \"sessions\".\n",
    "\n",
    "If we look at the variables in transactions and the new sessions entity, we see two more operations that were performed automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es[\"transactions\"].variables\n",
    "es[\"sessions\"].variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. It removed \"device\", \"customer_id\", \"zip_code\" and \"join_date\" from \"transactions\" and created a new variables in the sessions entity. This reduces redundant information as the those properties of a session don't change between transactions.\n",
    "2. It copied and marked \"session_start\" as a time index variable into the new sessions entity to indicate the beginning of a session. If the base entity has a time index and ``make_time_index`` is not set, ``normalize entity`` will create a time index for the new entity.  In this case it would create a new time index called \"first_transactions_time\" using the time of the first transaction of each session. If we don't want this time index to be created, we can set ``make_time_index=False``.\n",
    "\n",
    "If we look at the dataframes, can see what the ``normalize_entity`` did to the actual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es[\"sessions\"].df.head(5)\n",
    "es[\"transactions\"].df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To finish preparing this dataset, create a \"customers\" entity using the same method call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = es.normalize_dataframe(\n",
    "    base_dataframe_name=\"sessions\",\n",
    "    new_dataframe_name=\"customers\",\n",
    "    index=\"customer_id\",\n",
    "    make_time_index=\"join_date\",\n",
    "    additional_columns=[\"zip_code\", \"join_date\"],\n",
    ")\n",
    "\n",
    "es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the EntitySet\n",
    "\n",
    "Finally, we are ready to use this EntitySet with any functionality within Featuretools. For example, let's build a feature matrix for each product in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix, feature_defs = ft.dfs(entityset=es, target_dataframe=\"products\")\n",
    "\n",
    "feature_matrix"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "As we can see, the features from DFS use the relational structure of our entity set. Therefore it is important to think carefully about the entities that we create.\n",
    "\n",
    "Dask and Koalas EntitySets\n",
    "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "EntitySets can also be created using Dask dataframes or Koalas dataframes. For more information refer to :doc:`../guides/using_dask_entitysets` and :doc:`../guides/using_koalas_entitysets`."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
